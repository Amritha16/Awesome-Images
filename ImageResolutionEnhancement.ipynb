{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLPackage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amritha16/ImageResolutionEnhancement/blob/master/ImageResolutionEnhancement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQVG78zcFJfy",
        "colab_type": "text"
      },
      "source": [
        "This project is a tensorflow implementation of https://arxiv.org/pdf/1501.00092.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQuqAQkoEp8z",
        "colab_type": "text"
      },
      "source": [
        "The data for this project is stored in a github repository. Hence, the repo is being cloned to enable the access of that data. The data is in the form of .jpeg files.\n",
        "\n",
        "Data : https://github.com/Amritha16/ImageResolutionEnhancement\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGWW5PXZ7R6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5883d5ee-92c0-44dc-814d-14181b958d24"
      },
      "source": [
        "!git clone https://github.com/Amritha16/ImageResolutionEnhancement.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ImageResolutionEnhancement' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExC21z_ohcPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r ImageResolutionEnhancement/Result\n",
        "!mkdir ImageResolutionEnhancement/Result\n",
        "!rm -r ImageResolutionEnhancement/Model\n",
        "!mkdir ImageResolutionEnhancement/Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOSKDxB1FeW3",
        "colab_type": "text"
      },
      "source": [
        "Import the required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5mCvwXEEnoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os                                                                    \n",
        "import math \n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import tensorflow.compat.v1 as tf                                               \n",
        "tf.disable_v2_behavior()                                                        # DISABLED TO ENABLE PLACEHOLDERS\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Oc2kLQhyOz3",
        "colab_type": "text"
      },
      "source": [
        "All the appropriate directories are set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqdMXmaKF4Gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT_DIR = os.path.abspath('ImageResolutionEnhancement/')                       # ROOT DIRECTORY IS SET\n",
        "DATA_DIR = ROOT_DIR\n",
        "TRAIN_DIR = os.path.join(ROOT_DIR, 'Train/')                                    \n",
        "TEST_DIR = os.path.join(ROOT_DIR, 'Test/')\n",
        "OUT_DIR = os.path.join(ROOT_DIR, 'Result/')\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, 'Model/')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY3SK6kPMXVr",
        "colab_type": "text"
      },
      "source": [
        "Setting global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbE9IVWOLMId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 128\n",
        "\n",
        "NUM_EPOCHS = 20                                                                 # MAXIMUM NUMBER OF ITERATIONS IS SET TO 20\n",
        "INITIAL_LEARNING_RATE = 0.0001                                                  # LOW LEARNING RATE IS SET FOR MORE ACCURATE RESULTS\n",
        "\n",
        "READ_SIZE = 242\n",
        "INPUT_SIZE = 33\n",
        "OUTPUT_SIZE = 21\n",
        "SCALE = 3\n",
        "DIM = 1\n",
        "PAD = int((INPUT_SIZE - OUTPUT_SIZE)/2)\n",
        "STRIDE = 14\n",
        "\n",
        "SUB_IMG = int(math.floor((READ_SIZE-INPUT_SIZE)/STRIDE) + 1)\n",
        "NUM_SUBIMG = int(math.pow(SUB_IMG, 2))\n",
        "BATCH_SIZE = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F016PJFWP4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cropFunction(image, scale=3):\n",
        "    if image.shape[2] == 3:\n",
        "        size = image.shape                                                      # ALL THE IMAGES ARE SET TO SAME SCALE\n",
        "        size -= np.mod(size, scale)\n",
        "        image = image[0:size[0], 0:size[1]]\n",
        "        return image\n",
        "\n",
        "def im2double(im):                                                              # DATA TYPE \n",
        "    info = np.iinfo(im.dtype) \n",
        "    return im.astype(np.float) / info.max\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K57PO-hYG5OF",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing the data using sparse coding methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYPdZz9TWTVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DATA():                                                                   \n",
        "\n",
        "    def __init__(self, dirname):\n",
        "        self.dirPath = os.path.join(DATA_DIR, dirname)\n",
        "        self.filelist = os.listdir(self.dirPath)\n",
        "        self.size = len(self.filelist)\n",
        "        self.fileIndex = 0\n",
        "        self.dataIndex = 0\n",
        "        self.batch = None\n",
        "        self.batchLabel = None\n",
        "\n",
        "    def readImage(self, filename):                                               # IMAGE IS READ\n",
        "        img = cv2.imread(filename, 3)\n",
        "        ht, wd, channels = img.shape\n",
        "        ycr_cb_img = cv2.cvtColor(cv2.resize(img, (READ_SIZE, READ_SIZE)), cv2.COLOR_BGR2YCR_CB)\n",
        "        return ycr_cb_img\n",
        "\n",
        "    def preprocessImage(self, img):                                              # IMAGE IS PREPROCESSED\n",
        "        img = im2double(img)\n",
        "        Labels = cropFunction(img, SCALE)\n",
        "        bicubic_img = cv2.resize(img, None, fx=1.0/SCALE, fy=1.0/SCALE, interpolation=cv2.INTER_CUBIC)\n",
        "        Inputs = cv2.resize(bicubic_img, None, fx=SCALE/1.0, fy=SCALE/1.0, interpolation=cv2.INTER_CUBIC)\n",
        "        Inputs = Inputs[:, :, 0]                                                # INPUT IMAGE IS RESIZED\n",
        "        Labels = Labels[:, :, 0]\n",
        "        return Inputs, Labels\n",
        "\n",
        "    def processImage(self, file):                                                # IMAGE IS PROCESSED\n",
        "        self.batch = []\n",
        "        self.batchLabel = []\n",
        "        img = self.readImage(os.path.join(DATA_DIR, self.dirPath, file))\n",
        "        Inputs, Labels = self.preprocessImage(img)                               # PREPROCESS FUNCTION IS CALLED\n",
        "        xx = yy = 0\n",
        "        for i in range(0, READ_SIZE - INPUT_SIZE, STRIDE):\n",
        "            xx += 1\n",
        "            yy = 0\n",
        "            for j in range(0, READ_SIZE - INPUT_SIZE, STRIDE):                  \n",
        "                yy += 1                                                         \n",
        "                subInput = Inputs[i:(i+INPUT_SIZE), j:(j+INPUT_SIZE)]\n",
        "                subLabel = Labels[(i+PAD):(i+PAD+OUTPUT_SIZE), (j+PAD):(j+PAD+OUTPUT_SIZE)]\n",
        "                subInput = np.reshape(subInput, (INPUT_SIZE, INPUT_SIZE, DIM))      # EVERY ELEMENT AND LABEL IN ARRAY IS RESHAPED \n",
        "                subLabel = np.reshape(subLabel, (OUTPUT_SIZE, OUTPUT_SIZE, DIM))   \n",
        "                self.batch.append(subInput)                                    # VALUES ARE APPENDED BACK TO THE BATCH\n",
        "                self.batchLabel.append(subLabel)\n",
        "\n",
        "    def generate_batch(self):                                                   # BATCH IS GENERATED\n",
        "        if self.dataIndex >= (NUM_SUBIMG-1) or self.batch is None:\n",
        "            self.dataIndex = 0\n",
        "            self.processImage(self.filelist[self.fileIndex])\n",
        "            self.fileIndex = (self.fileIndex + 1) % self.size\n",
        "        batch = np.asarray(self.batch[self.dataIndex:(self.dataIndex+BATCH_SIZE)])\n",
        "        label = np.asarray(self.batchLabel[self.dataIndex:(self.dataIndex+BATCH_SIZE)])\n",
        "        self.dataIndex = self.dataIndex + BATCH_SIZE\n",
        "        return batch, label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYkCwFKnWZcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DataTests():\n",
        "    data = DATA(TEST_DIR)                                                       # TEST DATA IS SELECTED FROM IT'S DIRECTORY\n",
        "    for i in range(int(2*(NUM_SUBIMG / BATCH_SIZE))):\n",
        "        batch, label = data.generate_batch()\n",
        "        print(batch.shape)\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXa-rX9KJZ4D",
        "colab_type": "text"
      },
      "source": [
        "Image reconstruction occurs below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khy3KDw7Wc58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reconstruct(image, file):                                                   # IMAGE IS RECONSTRUCTED\n",
        "    savePath = os.path.join(OUT_DIR, file[:-4] + \"reconstructed.jpg\")\n",
        "    print(\"savePath \", savePath)\n",
        "    cv2.imwrite(savePath, image)\n",
        "\n",
        "def deprocess(imgs):                                                            # DEPROCESSED\n",
        "    imgs = imgs * 255\n",
        "    imgs[imgs > 255] = 255\n",
        "    imgs[imgs < 0] = 0\n",
        "    return imgs.astype(np.uint8)\n",
        "\n",
        "def stitch(patches):                                                            # ALL THE PACHES ARE STICHED TO A SINGLE OUTPUT IMAGE\n",
        "    image = np.zeros((SUB_IMG*OUTPUT_SIZE, SUB_IMG*OUTPUT_SIZE, DIM))\n",
        "    for ind, patch in enumerate(patches):\n",
        "        j = ind % SUB_IMG\n",
        "        i = ind // SUB_IMG\n",
        "        image[i*OUTPUT_SIZE:(i*OUTPUT_SIZE+OUTPUT_SIZE), j*OUTPUT_SIZE:(j*OUTPUT_SIZE+OUTPUT_SIZE), :] = patch\n",
        "    image = deprocess(image)\n",
        "    return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioBIAv0WJst2",
        "colab_type": "text"
      },
      "source": [
        "Defining layers in CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdYn6zBFW5ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Layer():\n",
        "\n",
        "    def __init__(self, shape, mean, stddev):                                    # INITIALLY RANDOM VALUES ARE SET TO THE WEIGHTS\n",
        "        self.weights = tf.Variable(tf.random_normal(shape=shape, mean=mean, stddev=stddev))\n",
        "        self.biases = tf.Variable(tf.zeros(shape=[shape[-1]]))                  # ZEROS ARE SET TO BIASES\n",
        "\n",
        "    def feedForward(self, inputData, stride=None):          \n",
        "        raise NotImplementedError                                               # HANDLING EXCEPTION\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnJI2p2kW9fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvolutionalLayer(Layer):                                                 # CONVOLUTION LAYER CONSTRUCTION\n",
        "\n",
        "    def __init__(self, shape, mean, stddev):\n",
        "        super(ConvolutionalLayer, self).__init__(shape, mean, stddev)\n",
        "\n",
        "    def feedForward(self, inputData, stride):                                 # FEED FORWARDS APPROX THE INPUT FUNCS\n",
        "        conv = tf.nn.conv2d(inputData, self.weights, stride, padding=\"VALID\")\n",
        "        output_data = tf.nn.relu(tf.nn.bias_add(conv, self.biases))\n",
        "        return output_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8InXVH9eXAbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OutputLayer(Layer):                                                      # OUTER LAYER GENERATION \n",
        "\n",
        "    def __init__(self, shape, mean, stddev):\n",
        "        super(OutputLayer, self).__init__(shape, mean, stddev)\n",
        "\n",
        "    def feedForward(self, inputData, stride):\n",
        "        Output_Data = tf.nn.bias_add(tf.nn.conv2d(inputData, self.weights, stride, padding=\"VALID\"), self.biases)\n",
        "        return Output_Data                                                      # BIAS IS RESTRICTED TO 1-D "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHB08W5131P9",
        "colab_type": "text"
      },
      "source": [
        "The Super-Resolution Convolutional Neural Network model :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmAHfEt2XCQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MODEL():                                                                  \n",
        "\n",
        "    def __init__(self):\n",
        "        self.inputs = tf.placeholder(shape=[None, INPUT_SIZE, INPUT_SIZE, DIM], dtype=tf.float32)\n",
        "        self.labels = tf.placeholder(shape=[None, OUTPUT_SIZE, OUTPUT_SIZE, DIM], dtype=tf.float32)\n",
        "        self.logits = None                                                      # PLACEHOLDER IS SET TO THE TENSORFLOW\n",
        "        self.output = None\n",
        "        self.loss = None\n",
        "\n",
        "    def build(self):\n",
        "        inputData = self.inputs                                                # THE PATCH EXTRACTION AND AGGREGATION ARE\n",
        "                                                                                # ALSO FORMULATED AS CONVOLUTIONAL LAYERS\n",
        "        conv1 = ConvolutionalLayer(shape= [9, 9, DIM, 64], mean = 0.0, stddev = 0.001)     \n",
        "        h = conv1.feedForward(inputData=inputData, stride=[1, 1, 1, 1])\n",
        "        conv2 = ConvolutionalLayer(shape = [1, 1, 64, 32], mean = 0.0, stddev = 0.001)\n",
        "        h = conv2.feedForward(inputData=h, stride=[1, 1, 1, 1])\n",
        "        outerLayer = OutputLayer(shape = [5, 5, 32, DIM], mean = 0.0, stddev = 0.001)\n",
        "        self.output = outerLayer.feedForward(inputData=h, stride=[1, 1, 1, 1])\n",
        "        self.loss = tf.reduce_mean(tf.squared_difference(self.labels, self.output))\n",
        "\n",
        "    def train(self, data):                                                      # TRAIN MODEL\n",
        "        opt = tf.train.AdamOptimizer(INITIAL_LEARNING_RATE).minimize(self.loss)\n",
        "        saver = tf.train.Saver()                                                # MODEL IS TRAINED WITH THE MINIMUM LEARNING RATE\n",
        "        with tf.Session() as session:\n",
        "            session.run(tf.global_variables_initializer())\n",
        "            print('All variables are Initialized')\n",
        "            for epoch in range(NUM_EPOCHS):                                     # ITERATED  OVER THE EPOCH COUNT\n",
        "                avgCost = 0                                                    \n",
        "                totalBatch = 0                                                 # TOTAL BATCH IS SET TO 0 FOR EACH EPOCH ITERATION\n",
        "                for batch in range(int(data.size*(NUM_SUBIMG / BATCH_SIZE))):\n",
        "                    batch_X, batch_Y = data.generate_batch()\n",
        "                    feedDict = {self.inputs: batch_X, self.labels: batch_Y}    # TO FEED VALUE TO TF PLACEHOLDERS\n",
        "                    _, lossValue = session.run([opt, self.loss], feed_dict=feedDict)\n",
        "                    totalBatch += 5\n",
        "                    avgCost += lossValue                                        # VALUE LOST IS SUMMED TO THE AVG COST \n",
        "                avgCost = avgCost / totalBatch\n",
        "                print(\"Epoch : \", (epoch + 1), \"cost = \", \"{:.3f}\".format(avgCost))\n",
        "\n",
        "            savePath = saver.save(session, os.path.join(MODEL_DIR, \"model\" + str(BATCH_SIZE) + \"_\" + str(NUM_EPOCHS) + \".ckpt\"))\n",
        "            print(\"Model saved in path: %s\" % savePath)\n",
        "\n",
        "    def test(self, data):                                                       # TEST MODEL\n",
        "        tempSaver = tf.train.Saver()\n",
        "        with tf.Session() as session:\n",
        "            tempSaver.restore(session, os.path.join(MODEL_DIR, \"model\" + str(BATCH_SIZE) + \"_\" + str(NUM_EPOCHS) + \".ckpt\"))\n",
        "            avgCost = 0                                                        # AVG COST IS SET TO 0 FOR EACH ITERATION\n",
        "            totalBatch = int(data.size*(NUM_SUBIMG / BATCH_SIZE))\n",
        "            for batch in range(totalBatch):\n",
        "                batch_x, batch_y = data.generate_batch()                        # X, Y BATCHES ARE GENERATED FOR THE DATA\n",
        "                feedDict = {self.inputs: batch_x, self.labels: batch_y}\n",
        "                pred_y, loss = session.run([self.output, self.loss], feed_dict=feedDict)\n",
        "                avgCost += loss      \n",
        "            avgCost = avgCost / totalBatch\n",
        "            print(\"cost =\", \"{:.3f}\".format(avgCost))\n",
        "\n",
        "    def SRGenerate(self, data):                                                # SUPER RESOLUTION IMAGE GENERATION\n",
        "        tempSaver = tf.train.Saver()\n",
        "        with tf.Session() as session:\n",
        "            tempSaver.restore(session, os.path.join(MODEL_DIR, \"model\" + str(BATCH_SIZE) + \"_\" + str(NUM_EPOCHS) + \".ckpt\"))\n",
        "            for file in data.filelist:\n",
        "                data.processImage(file)                                          # IMAGE IS PROCESSED AS BINARY ELEMENTS IN THE ARRAY\n",
        "                batch = np.asarray(data.batch)\n",
        "                feedDict = {self.inputs: batch}\n",
        "                all_patches = session.run(self.output, feed_dict=feedDict)         # IMAGE IS SPLIT AS PATCHES \n",
        "                #display_batch_patch(batch, patches)\n",
        "                image = stitch(all_patches)\n",
        "                reconstruct(image, file)                                        # IMAGE IS RECONSTRUCTED FROM PATCHES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYOIn4jDL0BC",
        "colab_type": "text"
      },
      "source": [
        "Main module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA3tKQfjXMpE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "39d8e1e9-7cd2-4383-e744-5434b4a9311f"
      },
      "source": [
        "def main():\n",
        "    train_data = DATA(TRAIN_DIR)                                                \n",
        "    model = MODEL()                                                             \n",
        "    model.build()                                                               # BUILD MODEL\n",
        "    \n",
        "    model.train(train_data)                                                     # TRAIN MODEL\n",
        "    \n",
        "    test_data = DATA(TEST_DIR)                                                  # TEST MODEL\n",
        "    model.test(test_data)\n",
        "    model.SRGenerate(test_data)                                                 # SUPERRESOLUTION GENERATE\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "    main()                                                                      # MAIN MODULE\n",
        "                                                                                                                "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All variables are Initialized\n",
            "Epoch :  1 cost =  0.003\n",
            "Epoch :  2 cost =  0.002\n",
            "Epoch :  3 cost =  0.002\n",
            "Epoch :  4 cost =  0.002\n",
            "Epoch :  5 cost =  0.002\n",
            "Epoch :  6 cost =  0.002\n",
            "Epoch :  7 cost =  0.002\n",
            "Epoch :  8 cost =  0.002\n",
            "Epoch :  9 cost =  0.002\n",
            "Epoch :  10 cost =  0.002\n",
            "Epoch :  11 cost =  0.002\n",
            "Epoch :  12 cost =  0.002\n",
            "Epoch :  13 cost =  0.002\n",
            "Epoch :  14 cost =  0.002\n",
            "Epoch :  15 cost =  0.002\n",
            "Epoch :  16 cost =  0.002\n",
            "Epoch :  17 cost =  0.002\n",
            "Epoch :  18 cost =  0.002\n",
            "Epoch :  19 cost =  0.002\n",
            "Epoch :  20 cost =  0.002\n",
            "Model saved in path: /content/ImageResolutionEnhancement/Model/model5_20.ckpt\n",
            "INFO:tensorflow:Restoring parameters from /content/ImageResolutionEnhancement/Model/model5_20.ckpt\n",
            "cost = 0.010\n",
            "INFO:tensorflow:Restoring parameters from /content/ImageResolutionEnhancement/Model/model5_20.ckpt\n",
            "savePath  /content/ImageResolutionEnhancement/Result/Img5reconstructed.jpg\n",
            "savePath  /content/ImageResolutionEnhancement/Result/Img2reconstructed.jpg\n",
            "savePath  /content/ImageResolutionEnhancement/Result/Img6reconstructed.jpg\n",
            "savePath  /content/ImageResolutionEnhancement/Result/Img7reconstructed.jpg\n",
            "savePath  /content/ImageResolutionEnhancement/Result/Img3reconstructed.jpg\n",
            "savePath  /content/ImageResolutionEnhancement/Result/Img8reconstructed.jpg\n",
            "savePath  /content/ImageResolutionEnhancement/Result/Img1reconstructed.jpg\n",
            "savePath  /content/ImageResolutionEnhancement/Result/Img4reconstructed.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}